**SENG 438 - Software Testing, Reliability, and Quality**

**Lab. Report #3 â€“ Code Coverage, Adequacy Criteria and Test Case Correlation**

| Group 12:      |     |
| -------------- | --- |
| Student Names: |     |
|Esohe Aideyan       |  30135560   |
|Jack Barrie         |  30088832   |
|Tamunomiete Brown   |     |
|Dyenaan Dapoet      |  30126758   |

# 1 Introduction

The objective of this assignment was to get familiar with white-box coverage testing by using different testing tools to analyze methods. We made use of different coverage tools, covering three different coverage metrics to test the Range and DataUtilities classes. Data Flow Coverage was manually conducted as well which helped us gain better understanding of how coverage tools work. Finally, test suites were updated to improve coverage to fit the adequacy criteria.

# 2 Manual data-flow coverage calculations for X and Y methods
DataUtilities.calculateColumnTotal

Data flow graph

![image](https://user-images.githubusercontent.com/91904892/222872852-f039a4a5-6ff6-4cdb-aca1-caff56c7c2a1.png)
Def-use sets per statement

![image](https://user-images.githubusercontent.com/91904892/222872859-966709a8-4679-44cc-b5c7-5cc4ad3b2bde.png)
DU-pairs per variable

![image](https://user-images.githubusercontent.com/91904892/222872879-aaacdfc4-2e0e-457b-a341-c8f0fc66bb03.png)

Pairs covered per test case

![image](https://user-images.githubusercontent.com/91904892/222872892-e482b6c4-ddcc-4daf-af4d-98cdc7560e32.png)

DU-pair Coverage Calculation

![image](https://user-images.githubusercontent.com/91904892/222874405-fce17ceb-7929-4a32-a4c6-9d7836919dc2.png)


Range.getLowerBound

Data Flow graph
![image](https://user-images.githubusercontent.com/91904892/222873322-1a804bea-d6d7-408f-85fa-3949686da5aa.png)

Def-use sets per statement

![image](https://user-images.githubusercontent.com/91904892/222873387-9e0ea014-b3ba-4791-af4f-c79841f5dfe2.png)

DU-pairs per variable

![image](https://user-images.githubusercontent.com/91904892/222873403-5fe56c0e-6af8-400e-8577-06ce89a61d22.png)

Pairs covered per test case

![image](https://user-images.githubusercontent.com/91904892/222873480-ee66292f-2755-4960-b295-b23627636185.png)

DU-pair coverage calculation

![image](https://user-images.githubusercontent.com/91904892/222874461-3f38b5de-104a-41fc-bbbe-8bf8c160fa74.png)


# 3 A detailed description of the testing strategy for the new unit test
We approached the white box testing by first viewing the code coverage of the tests we wrote for assignment 2. If the coverage wasnt acceptable, we wrote additional tests for those methods. Then we worked on writing new tests to cover the remaining code in the classes Range and DataUtilities. We used EclEmma in eclipse to see the coverage. We then went method by method writing tests, until we reached sufficient coverage for the classes.

# 4 A high level description of five selected test cases you have designed using coverage information, and how they have increased code coverage
Range: Range(lower, upper)
- The test cases for the Range constructor checked for invalid input, where the upper limit is less than the lower limit, which should throw a exception.
- We also tested that the upper and lower bounds were correctly set
- This resulted in 100% code coverage

Range: constrain(double)
- The test cases first looked at if the range contained the value, which tests the if(!contains(value)) statement
- Then the test cases looked at the two branches within the if statement, first where the value is greater than the upper bound then when it is less than the lower bound. This approach resulted in most of the code being covered

Range: combine(Range, Range)
- The tests cases we wrote first covered either of the two ranges being null
- Then we wrote a test to cover the branch where neither range is null, which will result in a new range being created.
- This approach led to 100% code coverage

Range: scale(Range, double)
- We wrote a test to first cover when the double being passed is less than 0, which should throw an exception
- Then we covered the remaining code by a test that considered when the double is greater than 0
- This resulted in 100% code coverage

Range: equals(Object)
- The first branch we covered was the if statement checking if the passed object is an instance of Range.
- The next branch was testing to see if the upper bound of the passed object matches the calling objects upper bound
- The next branch was similar to the previous test, but testing the lower bound
- This approach resulted in 100% code coverage.


# 5 A detailed report of the coverage achieved of each class and method (a screen shot from the code cover results in green and red color would suffice)
![Screenshot 2023-03-03 135330](https://user-images.githubusercontent.com/85323597/222856567-0f259f49-d16f-4a64-821f-fc64db85519e.png)
![image](https://user-images.githubusercontent.com/85323597/222879005-70ee9042-7df6-4ec3-912e-6bd7b93dab92.png)


# 6 Pros and Cons of coverage tools used and Metrics you report

The tool we used was EclEmma

Pros:
- The tool is already included in Eclipse
- It is easy to use and generate coverage reports
- It provides code highlighting to show which parts of the code are covered, which arent, or if a branch is partly covered
- Shows coverage for each method

Cons:
- It doesnt show which partially covered branches are covered and which arent (ie. only says 2 of 4 branches covered)

# 7 A comparison on the advantages and disadvantages of requirements-based test generation and coverage-based test generation.

Requirements-based testing is better defined and easier to plan especially with working in a group, because test cases and conditions are gotten directly from requirements. However, it is not able to provide exhaustive testing i.e. more coverage compared to coverage-based test generation because it is scoped to just requirements.
Coverage-based testing allows us determine test cases that will enable us acheive a certain coverage i.e. because coverage is subjective, we're able to deal with certain aspects of the system/object under test which leaves room for flexibility resulting in more coverage compared to requirements-based testing. The downfalls of this however is it could leave to conflicting opinions when working in a group and it is time consuming.

# 8 A discussion on how the team work/effort was divided and managed

We decided that in this lab, we were all going to work on the assignment and then come together to review and learn from what each person resulted. This way, we were able to share ideas and knowledge and futher bring about clarification to the members who were confused about certain parts in the assignment. In the final collation, Dyenaan worked on the data flow diagram and calculations, while the rest of us collated and worked on the tests (Jack, Esohe and Tammie).

# 9 Any difficulties encountered, challenges overcome, and lessons learned from performing the lab

During the course of this lab, we encountered a few difficulties which mainly stemmed from understanding what the lab was about. It took us so time to understand the lab and finally start working on it, to understand we all carried out personal research and readings to get familiar with some concepts and terminology used in this lab, from doing those readings we learned a lot about coverage tools and metrics which became very useful in completeing the lab.
Another difficulty we encountered while working on the lab was understanding the features and properties of the various coverage tools our group decided to use for the lab. To overcome this problem, we utilized resources such as youtube and the coverage tools companies support documents to improve familiarity with the tools. We learnt how powerful and useful coverage tools are especially in discovering the scope of a test suite.

# 10 Comments/feedback on the lab itself

This lab was very engaging and gave an inside look to some tools and practices Quality Assurance professionals would use in the span of their career. It also helped to solidify our understanding of coverage tools, metrics data-flow graphs etc. To improve this lab, I would suggest more information on some certain instructions as some of the instructions were vague and not very detailed, overall it was an amazing lab!
